<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bardia Koopah</title><link>https://www.bardiak.com/</link><description>Recent content on Bardia Koopah</description><generator>Hugo</generator><language>en-us</language><atom:link href="https://www.bardiak.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Personal</title><link>https://www.bardiak.com/personal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.bardiak.com/personal/</guid><description>&lt;h1 id="personal"&gt;Personal&lt;/h1&gt;
&lt;p&gt;I&amp;rsquo;m a &lt;span style="color:#FDB515 !important; font-weight:bold;"&gt;UC&lt;/span&gt;&lt;span style="color:#003262 !important; font-weight:bold;"&gt; Berkeley&lt;/span&gt; student studying CS. I&amp;rsquo;m currently doing Agentic AI research with Professors &lt;a href="https://people.eecs.berkeley.edu/~jegonzal/"&gt;Joey Gonzalez&lt;/a&gt; and &lt;a href="https://people.eecs.berkeley.edu/~alexdimakis/"&gt;Alex Dimakis&lt;/a&gt; at &lt;a href="https://sky.cs.berkeley.edu/" target="_blank"&gt;
&lt;span style="color:#FDB515 !important; font-weight:bold;"&gt;Sky&lt;/span&gt;&lt;span style="color:#003262 !important; font-weight:bold;"&gt;Lab&lt;/span&gt;
&lt;/a&gt;, mainly analyzing tool use within agents. My interests broadly span most things ML, primarily LLM&amp;rsquo;s and Optimization, whether they are used for finance, robotics, vision applications, etc.&lt;/p&gt;
&lt;p&gt;For an overview of my past and present work experiences, check out my LinkedIn (which I try and keep up-to-date), available on the sidebar.&lt;/p&gt;</description></item><item><title>Projects</title><link>https://www.bardiak.com/projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.bardiak.com/projects/</guid><description>&lt;h1 id="projects"&gt;Projects&lt;/h1&gt;
&lt;div class="projects-grid"&gt;
 &lt;!-- Transformer from Scratch --&gt;
 &lt;div class="project-card"&gt;
 &lt;h2&gt;Transformer from Scratch&lt;/h2&gt;
 &lt;p class="project-subtitle"&gt;PyTorch • Multi30k • Full encoder–decoder architecture&lt;/p&gt;
 &lt;p class="project-description"&gt;
 Implemented a full Transformer model from scratch in PyTorch, including
 multi-head attention, positional encodings, custom tokenizers, and a training
 loop on the Multi30k dataset. Focused on reproducing “Attention is All You Need”
 details and understanding every component end-to-end.
 &lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/BardiaKoopah/my-transformer-from-scratch"&gt;Transformer Project Github Link&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;"&gt;
 &lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/aVSwxn7r2p8?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"&gt;&lt;/iframe&gt;
 &lt;/div&gt;

&lt;/code&gt;&lt;/pre&gt;
 &lt;/div&gt;
&lt;/div&gt;</description></item><item><title>Publications</title><link>https://www.bardiak.com/publications/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.bardiak.com/publications/</guid><description>&lt;h1 id="publications"&gt;Publications&lt;/h1&gt;
&lt;p&gt;Currently working on two papers:&lt;/p&gt;
&lt;p&gt;Co-author of &lt;a href="https://www.tbench.ai/"&gt;&lt;strong&gt;Terminal Bench Report&lt;/strong&gt;&lt;/a&gt; paper through the &lt;a href="https://www.laude.org/"&gt;&lt;strong&gt;Laude Institute&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Co-author of Active Tools paper through Berkeley SkyLab.&lt;/p&gt;
&lt;p&gt;Will update with direct links soon&amp;hellip;&lt;/p&gt;</description></item></channel></rss>