<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Bardia Koopah | Projects</title>
    <link rel="stylesheet" href="/css/style.css">
    
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Bardia Koopah</h1>
		
		
        
			<img src="/bardia-pfp.png" alt="Logo" />
        
		

        
        <p></p>
        
		
        <div class="compact-sidebar">
		
        <p>
          <img src="/icons/mail-symbol.svg" class="octicons">
            
bkoop at berkeley dot edu

        </p>
		
    
    
        <p>
          <img src="/linkedin-icon.png" class="octicons">
          
www.linkedin.com/in/bardiakoopah


        </p>
    

    
    <p>
      <img src="/Octicons-mark-github.svg" class="octicons">
      
https://github.com/BardiaKoopah
    </p>
    

        </div>
		
		<hr/>
         
        
        <p> <a href="/personal/">Personal</a> </p>
        <p> <a href="/projects/">Projects</a> </p>
        <p> <a href="/publications/">Publications</a> </p>
          
        
      </header>

<section>
    <h1 id="projects">Projects</h1>
<div class="projects-grid">
  <!-- Transformer from Scratch -->
  <div class="project-card">
    <h2>Transformer from Scratch</h2>
    <p class="project-subtitle">PyTorch • Multi30k • Full encoder–decoder architecture</p>
    <p class="project-description">
      Implemented a full Transformer model from scratch in PyTorch, including
      multi-head attention, positional encodings, custom tokenizers, and a training
      loop on the Multi30k dataset. Focused on reproducing “Attention is All You Need”
      details and understanding every component end-to-end.
    </p>
<pre><code>[Transformer Project Github Link](https://github.com/BardiaKoopah/my-transformer-from-scratch)

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
          <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/aVSwxn7r2p8?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
        </div>

</code></pre>
  </div>
  <!-- GPT-2 From Scratch -->
  <div class="project-card">
    <h2>GPT-2 From Scratch</h2>
    <p class="project-subtitle">Decoder-only Transformer • Byte-level BPE • Full training pipeline reproduction</p>
    <p class="project-description">
      Reimplemented GPT-2 (12-layer, 768-dim, 12-head decoder-only Transformer) entirely from scratch in PyTorch,
      including a byte-level BPE tokenizer, custom dataloader, weight tying, causal self-attention,
      and a full training loop with learning rate warmup and cosine decay to reproduce the original paper’s setup.
      Focused on architectural fidelity, training stability, and performance benchmarking against WikiText-2,
      validating perplexity and scaling behavior end-to-end.
    </p>
<pre><code>[GPT-2 Project Github Link](https://github.com/BardiaKoopah/GPT-2_from_scratch)

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
          <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/DgfKK0ipZOc?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
        </div>

</code></pre>
  </div>
</div>

</section>
<head>
    <style>
        footer {height: 2cm;}
    </style>
</head>

<footer>
    <p1><small>Copyright © Bardia Koopah</small></p1>
    <p><small>Last updated on Feb 17, 2026</small></p>
    <p><small>This guy makes a cool <a href="http://hyren.me/">website</a></small></p>
</footer>
</div>
<script src="/js/scale.fix.js"></script>
<script data-goatcounter="https://.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>
</body>
</html>

